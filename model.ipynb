{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e8bd578",
   "metadata": {},
   "source": [
    "# Model selection\n",
    "\n",
    "Tested models:\n",
    "- k-Nearest Neighbours,\n",
    "- Random Forest,\n",
    "- Decision Tree,\n",
    "- Artificial Neural Network,\n",
    "- k-Means.\n",
    "\n",
    "For each model there was also a test which meant to balance dataset to even or near-even number of samples for sessions with and without a purchase - 40% purchase, 60% non purchase, opposite, but also even split.\n",
    "\n",
    "Best predictions score on evaluation stage was achieved for 6:4 ratio of dataset (60% non-purchase, 40% purchase sessions) with 90% correct predictions for non-purchase sessions and 84.4% for sessions with purchase. Second best model was artificial neural network using custom generator to pull balanced data directly from entire dataset in each epoch. This model achieved 91.9% correct predictions for sessions without purchase and 71.4% correct predictions for sessions with purchase and 94.2% correct predictions for sessions without purchase and 68.3% correct predictions for sessions with purchase after lowering dropout and limiting training time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e163dac8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1584c947",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions (10% evaluation data): 0.8933962264150943, 0.8497109826589595\n",
      "Correct predictions (10% evaluation data): 0.8806262230919765, 0.8151658767772512\n",
      "Correct predictions (10% evaluation data): 0.8740384615384615, 0.8290155440414507\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "x, y = utils.load_data()\n",
    "for k in range(3):\n",
    "    x, y = shuffle(x, y)\n",
    "    x_train, x_eva, y_train, y_eva = train_test_split(x, y, test_size=0.1)\n",
    "    x_train, y_train = utils.balance_data(x_train, y_train, ratio=(0.6, 0.4))\n",
    "    clf = RandomForestClassifier(random_state=0)\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    predictions = clf.predict(x_eva)\n",
    "    eva_score = [0, 0]\n",
    "    eva_len = [0, 0]\n",
    "    for i in range(len(predictions)):\n",
    "        if np.argmax(predictions[i]) == np.argmax(y_eva[i]):\n",
    "            eva_score[np.argmax(predictions[i])] += 1\n",
    "        if np.argmax(y_eva[i]) == 0:\n",
    "            eva_len[0] += 1\n",
    "        else:\n",
    "            eva_len[1] += 1\n",
    "    print(\"Correct predictions (10% evaluation data): \"+str(eva_score[0]/eva_len[0])+\", \"+str(eva_score[1]/eva_len[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57aab00",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# Artificial Neural Network with generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dc8671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import utils\n",
    "\n",
    "batch_size = 16\n",
    "ratio = 0.5\n",
    "x, y = utils.load_data()\n",
    "x, y = shuffle(x, y)\n",
    "x_train, x_eva, y_train, y_eva = train_test_split(x, y, test_size=0.1)\n",
    "x1, x2, y1, y2 = utils.separate_data(x_train, y_train)\n",
    "\n",
    "# defining model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=x[0].shape),\n",
    "    tf.keras.layers.Dense(units=32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=8, activation=\"tanh\"),\n",
    "    tf.keras.layers.Dense(units=8, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=8, activation=\"tanh\"),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(units=8, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(units=2, activation=\"softmax\")\n",
    "])\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=opt, loss='mse', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def lr_rate_schedule(epochs, lr):\n",
    "    if epochs < 1000:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr*0.1\n",
    "    return lr\n",
    "\n",
    "\n",
    "class BalancedGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x1, x2, y1, y2, batch_size, ratio):\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "        self.y1 = y1\n",
    "        self.y2 = y2\n",
    "        self.batch_size = batch_size\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def __len__(self):\n",
    "        return (np.ceil((len(self.x1) + len(self.x2)) / float(self.batch_size))).astype(np.int)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x1[idx * int(self.batch_size * self.ratio): (idx + 1) * int(self.batch_size * self.ratio)]\n",
    "        batch_x.extend(self.x2[idx * int(self.batch_size * self.ratio): (idx + 1) * int(self.batch_size * self.ratio)])\n",
    "        batch_y = self.y1[idx * int(self.batch_size * self.ratio): (idx + 1) * int(self.batch_size * self.ratio)]\n",
    "        batch_y.extend(self.y2[idx * int(self.batch_size * self.ratio): (idx + 1) * int(self.batch_size * self.ratio)])\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_rate_schedule)  # variable lr\n",
    "log_dir = \"./logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # training graphs\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "training_batch_generator = BalancedGenerator(x1, x2, y1, y2, batch_size, ratio)\n",
    "\n",
    "for k in range(5):  # control overfit\n",
    "    model.fit(training_batch_generator, epochs=50, verbose=0, callbacks=[lr_callback]) #, tensorboard_callback])\n",
    "\n",
    "    # model evaluation\n",
    "    predictions = model.predict(np.asarray(x_eva))\n",
    "    eva_score = [0, 0]\n",
    "    eva_len = [0, 0]\n",
    "    for i in range(len(predictions)):\n",
    "        if np.argmax(predictions[i]) == np.argmax(y_eva[i]):\n",
    "            eva_score[np.argmax(predictions[i])] += 1\n",
    "        if np.argmax(y_eva[i]) == 0:\n",
    "            eva_len[0] += 1\n",
    "        else:\n",
    "            eva_len[1] += 1\n",
    "    print(\"Correct predictions (10% evaluation data): \"+str(eva_score[0]/eva_len[0])+\", \"+str(eva_score[1]/eva_len[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
